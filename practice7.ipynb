{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766e60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#overfitting / underfitting 을 조절하기 위해서 할 수 있는 방법\n",
    "#data를 추가하기 / early stop 사용하기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f7ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "# Compose 함수를 호출해서 사용한 randomhorizontalflip함수는 이미지를 무작위로 수평 뒤집기를 한다.\n",
    "# 이 함수만으로 이미지데이터가 2배가 된다.\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('./.data',train = True,download=True,transform=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.1307),(0.3081))])),batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('./.data',train = False,download=True,transform=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.1307),(0.3081))])),batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddb3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.5562495931625366 acc 82.45\n",
      "epoch 1 loss 0.4276498867034912 acc 86.67\n",
      "epoch 2 loss 0.35771887044906614 acc 88.54\n",
      "epoch 3 loss 0.30509262845516205 acc 90.31\n",
      "epoch 4 loss 0.2637909323215485 acc 91.83\n",
      "epoch 5 loss 0.2349925431907177 acc 92.63\n",
      "epoch 6 loss 0.21358354201316834 acc 93.38\n",
      "epoch 7 loss 0.19619987268447875 acc 93.98\n",
      "epoch 8 loss 0.18368469135761262 acc 94.15\n",
      "epoch 9 loss 0.17183201806545256 acc 94.57\n",
      "epoch 10 loss 0.16419848544597626 acc 94.9\n"
     ]
    }
   ],
   "source": [
    "#drop out\n",
    "#데이터뿐만 아니라 모델에 직접 영향을 줘서 과적합을 해결하는 드롭아웃 방법이 있다. 학습 도중 신경망의 일부를 사용하지 않는 방법.\n",
    "# 검증과 테스트 단계에서는 모든 뉴런을 사용하지만 학습뉴런을 몇개를 죽임으로서 다른 뉴런들의 가중치가 고이는 것을 방지할 수 있음\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,dropout_p=0.2):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "        #드롭아웃 확률 설정\n",
    "        self.dropout_p = dropout_p\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #드롭아웃 추가\n",
    "        x = F.dropout(x,training=self.training,p=self.dropout_p)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x,training=self.training,p=self.dropout_p)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Net(dropout_p=0.2).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01)\n",
    "\n",
    "def train(model,train_loader,optimizer):\n",
    "    model.train()\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        data,target = data.to(DEVICE),target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data,target = data.to(DEVICE),target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target,reduction = 'sum').item()\n",
    "            pred = output.max(1,keepdim = True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100*correct/len(test_loader.dataset)\n",
    "    return test_loss,test_acc\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(model,train_loader,optimizer)\n",
    "    test_loss,test_acc = evaluate(model,test_loader)\n",
    "    print('epoch',epoch,'loss',test_loss,'acc',test_acc)\n",
    "    \n",
    "#이 코드를 통해서 데이터의 추가와 dropout으로 인해서 정확도가 기존보다 상승하는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117fc81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
