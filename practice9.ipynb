{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5100bc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#복잡한 데이터셋을 처리하기 위한 깊은 모델 구축해보기\n",
    "#ResNet\n",
    "#컨볼루션층의 출력에 전의 전 (2단계 전)계층에 쓰였던 입력을 더해줘서 특징이 유실되지않게함\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./.data',train=True,download = True,transform=transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding = 4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])),batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./.data',train=False,download = True,transform=transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding = 4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])),batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "689b64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN을 깊게 쌓는 방법\n",
    "# 인공신경망을 여러개 쌓는다고 해서 학습 성능이 계속 좋아지진 않는다, 최초 입력 이미지에 대한 정보가 소실되기 때문이다.\n",
    "#ResNet은 이 문제를 해결하기 위하여 네트워크를 작은 블록인 Residual 블록으로 나눠서 사용한다.\n",
    "#Residual 블록의 출력에 입력이였던 x를 더함으로 모델을 훨씬 더 깊게 할 수 있다.\n",
    "#배치 정규화란, 학습률을 너무 높게 잡으면 기울기가 소실되거나 발산하는 증상을 예방하여 학습과정을 안정화하는 방법\n",
    "#이 모델에서는 자체적으로 정규화를 수행하여 드롭아웃과 같은 효과를 냄\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "#Sequential -> 여러 모듈 nn.Module 들을 하나로 묶어줘서 코드를 간결하게 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f958c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes = 10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=3,stride=1,padding=1,bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16,2,stride = 1)\n",
    "        self.layer2 = self._make_layer(32,2,stride = 2)\n",
    "        self.layer3 = self._make_layer(64,2,stride = 2)\n",
    "        self.linear = nn.Linear(64,num_classes)\n",
    "    def _make_layer(self,planes,num_block,stride):\n",
    "        strides = [stride]+[1]*(num_block-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes,planes,stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out,8)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc91e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 1.4037, Accuracy: 50.14%\n",
      "[2] Test Loss: 1.3798, Accuracy: 54.52%\n",
      "[3] Test Loss: 0.8521, Accuracy: 70.18%\n",
      "[4] Test Loss: 0.8813, Accuracy: 68.94%\n",
      "[5] Test Loss: 0.8648, Accuracy: 70.36%\n",
      "[6] Test Loss: 0.7899, Accuracy: 72.88%\n",
      "[7] Test Loss: 0.9586, Accuracy: 68.21%\n",
      "[8] Test Loss: 0.7940, Accuracy: 72.93%\n",
      "[9] Test Loss: 0.8706, Accuracy: 70.76%\n",
      "[10] Test Loss: 0.7360, Accuracy: 74.84%\n",
      "[11] Test Loss: 0.7745, Accuracy: 73.86%\n",
      "[12] Test Loss: 0.7296, Accuracy: 74.01%\n",
      "[13] Test Loss: 0.7972, Accuracy: 73.26%\n",
      "[14] Test Loss: 0.6730, Accuracy: 76.65%\n",
      "[15] Test Loss: 0.8414, Accuracy: 71.31%\n",
      "[16] Test Loss: 0.6636, Accuracy: 77.47%\n",
      "[17] Test Loss: 0.7420, Accuracy: 74.80%\n",
      "[18] Test Loss: 0.6589, Accuracy: 77.28%\n",
      "[19] Test Loss: 0.6252, Accuracy: 78.69%\n",
      "[20] Test Loss: 0.7091, Accuracy: 76.48%\n",
      "[21] Test Loss: 0.5946, Accuracy: 79.52%\n",
      "[22] Test Loss: 0.5949, Accuracy: 79.72%\n",
      "[23] Test Loss: 0.6155, Accuracy: 79.21%\n",
      "[24] Test Loss: 0.9510, Accuracy: 70.67%\n",
      "[25] Test Loss: 0.7526, Accuracy: 75.12%\n",
      "[26] Test Loss: 0.6800, Accuracy: 76.85%\n",
      "[27] Test Loss: 0.7099, Accuracy: 75.19%\n",
      "[28] Test Loss: 0.6437, Accuracy: 78.12%\n",
      "[29] Test Loss: 0.5591, Accuracy: 80.80%\n",
      "[30] Test Loss: 0.6865, Accuracy: 76.94%\n",
      "[31] Test Loss: 0.6401, Accuracy: 78.09%\n",
      "[32] Test Loss: 0.7020, Accuracy: 75.62%\n",
      "[33] Test Loss: 0.5584, Accuracy: 80.78%\n",
      "[34] Test Loss: 0.5778, Accuracy: 79.84%\n",
      "[35] Test Loss: 0.7503, Accuracy: 75.67%\n",
      "[36] Test Loss: 0.6872, Accuracy: 76.97%\n",
      "[37] Test Loss: 0.6560, Accuracy: 77.95%\n",
      "[38] Test Loss: 0.7889, Accuracy: 74.50%\n",
      "[39] Test Loss: 0.6423, Accuracy: 77.87%\n",
      "[40] Test Loss: 1.0028, Accuracy: 68.58%\n",
      "[41] Test Loss: 0.6373, Accuracy: 78.45%\n",
      "[42] Test Loss: 0.6122, Accuracy: 79.23%\n",
      "[43] Test Loss: 0.8093, Accuracy: 73.55%\n",
      "[44] Test Loss: 0.5354, Accuracy: 81.97%\n",
      "[45] Test Loss: 0.5722, Accuracy: 80.01%\n",
      "[46] Test Loss: 0.6167, Accuracy: 78.68%\n",
      "[47] Test Loss: 0.6827, Accuracy: 76.83%\n",
      "[48] Test Loss: 0.6194, Accuracy: 78.85%\n",
      "[49] Test Loss: 0.6534, Accuracy: 77.29%\n",
      "[50] Test Loss: 0.3643, Accuracy: 87.54%\n",
      "[51] Test Loss: 0.3379, Accuracy: 88.71%\n",
      "[52] Test Loss: 0.3373, Accuracy: 88.37%\n",
      "[53] Test Loss: 0.3251, Accuracy: 88.91%\n",
      "[54] Test Loss: 0.3320, Accuracy: 88.78%\n",
      "[55] Test Loss: 0.3358, Accuracy: 88.40%\n",
      "[56] Test Loss: 0.3216, Accuracy: 89.30%\n",
      "[57] Test Loss: 0.3252, Accuracy: 89.01%\n",
      "[58] Test Loss: 0.3282, Accuracy: 89.05%\n",
      "[59] Test Loss: 0.3244, Accuracy: 88.99%\n",
      "[60] Test Loss: 0.3220, Accuracy: 89.05%\n",
      "[61] Test Loss: 0.3148, Accuracy: 89.29%\n",
      "[62] Test Loss: 0.3207, Accuracy: 89.29%\n",
      "[63] Test Loss: 0.3380, Accuracy: 88.68%\n",
      "[64] Test Loss: 0.3430, Accuracy: 88.46%\n",
      "[65] Test Loss: 0.3290, Accuracy: 88.88%\n",
      "[66] Test Loss: 0.3344, Accuracy: 88.37%\n",
      "[67] Test Loss: 0.3341, Accuracy: 88.78%\n",
      "[68] Test Loss: 0.3315, Accuracy: 88.75%\n",
      "[69] Test Loss: 0.3401, Accuracy: 88.82%\n",
      "[70] Test Loss: 0.3495, Accuracy: 88.22%\n",
      "[71] Test Loss: 0.3497, Accuracy: 88.36%\n",
      "[72] Test Loss: 0.3371, Accuracy: 88.44%\n",
      "[73] Test Loss: 0.3422, Accuracy: 88.70%\n",
      "[74] Test Loss: 0.3459, Accuracy: 88.51%\n",
      "[75] Test Loss: 0.3798, Accuracy: 87.44%\n",
      "[76] Test Loss: 0.3447, Accuracy: 88.81%\n",
      "[77] Test Loss: 0.3762, Accuracy: 87.78%\n",
      "[78] Test Loss: 0.3541, Accuracy: 88.40%\n",
      "[79] Test Loss: 0.3795, Accuracy: 87.51%\n",
      "[80] Test Loss: 0.3604, Accuracy: 88.36%\n",
      "[81] Test Loss: 0.3449, Accuracy: 88.46%\n",
      "[82] Test Loss: 0.3661, Accuracy: 88.12%\n",
      "[83] Test Loss: 0.4092, Accuracy: 86.94%\n",
      "[84] Test Loss: 0.3631, Accuracy: 87.51%\n",
      "[85] Test Loss: 0.3566, Accuracy: 88.29%\n",
      "[86] Test Loss: 0.3498, Accuracy: 88.58%\n",
      "[87] Test Loss: 0.3485, Accuracy: 88.34%\n",
      "[88] Test Loss: 0.3604, Accuracy: 88.12%\n",
      "[89] Test Loss: 0.4500, Accuracy: 85.57%\n",
      "[90] Test Loss: 0.3571, Accuracy: 88.10%\n",
      "[91] Test Loss: 0.3981, Accuracy: 86.96%\n",
      "[92] Test Loss: 0.3570, Accuracy: 88.30%\n",
      "[93] Test Loss: 0.3662, Accuracy: 87.70%\n",
      "[94] Test Loss: 0.3466, Accuracy: 88.43%\n",
      "[95] Test Loss: 0.3786, Accuracy: 87.52%\n",
      "[96] Test Loss: 0.3651, Accuracy: 88.09%\n",
      "[97] Test Loss: 0.3745, Accuracy: 87.53%\n",
      "[98] Test Loss: 0.3919, Accuracy: 87.28%\n",
      "[99] Test Loss: 0.3764, Accuracy: 87.89%\n",
      "[100] Test Loss: 0.2975, Accuracy: 90.16%\n"
     ]
    }
   ],
   "source": [
    "model = ResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.1,momentum=0.9,weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=50,gamma=0.1)\n",
    "# 학습률 감소 기법 lr_scheduler 를 이용하여 학습이 진행함에 따라 학습률을 감소시켜(50번 반복당 0.1곱하기) 학습률을 조정함\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            # 배치 오차를 합산\n",
    "            test_loss += F.cross_entropy(output, target,\n",
    "                                         reduction='sum').item()\n",
    "\n",
    "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    scheduler.step()\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bcf70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1b7de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
